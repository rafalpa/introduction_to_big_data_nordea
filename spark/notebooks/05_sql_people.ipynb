{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we actually go about writing our Spark Application, we are going to need a way to send user commands and data to it. We do that by first creating a __SparkSession__.\n",
    "When you start Spark in this interactive mode (__spark-shell__), you __implicitly__ create a SparkSession that manages the Spark Application. When you start it through a standalone application, you must create the SparkSession object yourself in your application code.\n",
    "\n",
    "The SparkSession instance is the way Spark executes user-defined\n",
    "manipulations across the cluster. There is a one-to-one correspondence between a SparkSession and\n",
    "a Spark Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Word Count\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old API, mainly for working on RDD\n",
    "# import pyspark\n",
    "# import pyspark.sql.functions as func\n",
    "# sc = pyspark.SparkContext(appName='people')\n",
    "# sqlContext = pyspark.sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = spark.read.json('data/people.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL and Dataframes\n",
    "\n",
    "Structured data is any data that has a schema — that is, a known set of fields for each record. Spark SQL provides a dataset abstraction that simplifies working with structured datasets. Dataset is similar to tables in a relational database. Dataset has a natural schema, and this let's Spark store data in a more efficient manner and can run SQL queries on it using actual SQL commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have to Register table first, before using it with spark SQL\n",
    "# Table alias can have any name\n",
    "people.registerTempTable('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can query \"people\" table\n",
    "r = spark.sql('SELECT * FROM people')\n",
    "# returns new DataFrame\n",
    "print(type(r))\n",
    "r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('SELECT name, age FROM people').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('SELECT * FROM people WHERE age > 30').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# you can use docstring for longer queries\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        gender,\n",
    "        count(*) AS count, \n",
    "        avg(age) AS avg_age, \n",
    "        avg(children) AS avg_children \n",
    "    FROM people\n",
    "    WHERE gender = 'male'\n",
    "    GROUP BY gender\n",
    "\"\"\"\n",
    "grouped_by_gender_sql = spark.sql(query)\n",
    "grouped_by_gender_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_gender_sql.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful, this one won't work\n",
    "#sqlContext.sql(\"SELECT name, surname, max(age) as maxAge FROM people WHERE gender = 'male'\").show()\n",
    "# But this works\n",
    "spark.sql(\"SELECT first(name) AS name, first(surname) AS surname, max(age) as maxAge FROM people WHERE gender = 'male'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Dataframe methods\n",
    "\n",
    "Alternatively to SQL queries, Spark Dataframes have methods corresponding to SQL syntax. \n",
    "They are more familiar to OOP methods and allow compiler/interpreter to catch many bugs (at compile time). \n",
    "SQL is simpler but many bugs can be caught at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.select('name', 'age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.where(people.age > 30).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_by_gender_df = people \\\n",
    "    .groupBy('gender') \\\n",
    "    .agg(func.avg('age').alias('avg_age'), \n",
    "         func.avg('children').alias('avg_children'))\n",
    "    \n",
    "grouped_by_gender_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_gender_df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.groupBy('gender').agg(func.avg('age').alias('avg_age'), func.max('children').alias('max_children')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.groupBy('gender').pivot('name').agg(func.avg('age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.where(people.gender == 'male') \\\n",
    "    .select(\n",
    "        func.first('name').alias('name'), \n",
    "        func.first('surname').alias('surname'), \n",
    "        func.max('age').alias('maxAge')) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add renamed column and sort\n",
    "people \\\n",
    "    .groupBy(\"gender\") \\\n",
    "    .avg(\"children\") \\\n",
    "    .withColumnRenamed(\"avg(children)\", \"children_avg\") \\\n",
    "    .sort(desc(\"children_avg\")) \\\n",
    "    .limit(5) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# Można otrzymywać data frame Pandas bezpośrednio z DataFrames; pamiętaj jednak o rozmiarze danych...\n",
    "p = people.groupBy('gender').agg(func.avg('age').alias('avg_age'), func.max('children').alias('max_children')) \\\n",
    "        .toPandas().set_index('gender')\n",
    "p.plot(kind='bar', figsize=(14,10))\n",
    "p"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
